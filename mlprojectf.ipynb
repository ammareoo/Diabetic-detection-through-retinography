{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import models, transforms\nfrom sklearn.metrics import cohen_kappa_score\nfrom PIL import Image\nimport os\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:01:42.280394Z","iopub.execute_input":"2023-12-05T20:01:42.281287Z","iopub.status.idle":"2023-12-05T20:01:42.286582Z","shell.execute_reply.started":"2023-12-05T20:01:42.281242Z","shell.execute_reply":"2023-12-05T20:01:42.285595Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n#GeM layer(contribution)\nfrom torch.nn.parameter import Parameter\n\ndef gem(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:01:42.299506Z","iopub.execute_input":"2023-12-05T20:01:42.300425Z","iopub.status.idle":"2023-12-05T20:01:42.308674Z","shell.execute_reply.started":"2023-12-05T20:01:42.300381Z","shell.execute_reply":"2023-12-05T20:01:42.307479Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# Load your train_csv and test_csv\ntrain_csv = pd.read_csv(\"/kaggle/input/aptos2019-blindness-detection/train.csv\")\ntest_csv = pd.read_csv(\"/kaggle/input/aptos2019-blindness-detection/test.csv\")\n\n# Define data paths\ntrainpath =\"/kaggle/input/aptos2019-blindness-detection/train_images\"\ntestpath = \"/kaggle/input/aptos2019-blindness-detection/test_images\"\n\n# Define transformation(contribution)\napply_transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ColorJitter(brightness=20, contrast=0.2, saturation=20, hue=10),\n    transforms.RandomAffine(degrees=180, scale=(1-0.2, 1+0.2), shear=0.2),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:01:42.315139Z","iopub.execute_input":"2023-12-05T20:01:42.315589Z","iopub.status.idle":"2023-12-05T20:01:42.349984Z","shell.execute_reply.started":"2023-12-05T20:01:42.315551Z","shell.execute_reply":"2023-12-05T20:01:42.348744Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Create tensors for images and labels\nTrainImages = torch.FloatTensor(len(train_csv), 3, 128, 128)\nTrainLabels = torch.LongTensor(len(train_csv))\nTestImages = torch.FloatTensor(len(test_csv), 3, 128, 128)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:01:42.352466Z","iopub.execute_input":"2023-12-05T20:01:42.352988Z","iopub.status.idle":"2023-12-05T20:01:42.368377Z","shell.execute_reply.started":"2023-12-05T20:01:42.352939Z","shell.execute_reply":"2023-12-05T20:01:42.367339Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess training images\nfor i in tqdm.tqdm(range(len(train_csv))):\n    img_name, label = train_csv.values[i]\n    img_path = os.path.join(trainpath, img_name + '.png')\n    image = Image.open(img_path)\n    image = apply_transform(image)\n    TrainImages[i] = image\n    TrainLabels[i] = label\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:01:42.369777Z","iopub.execute_input":"2023-12-05T20:01:42.370355Z","iopub.status.idle":"2023-12-05T20:11:59.932075Z","shell.execute_reply.started":"2023-12-05T20:01:42.370323Z","shell.execute_reply":"2023-12-05T20:11:59.929999Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 3662/3662 [10:17<00:00,  5.93it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load and preprocess test images\nfor i in tqdm.tqdm(range(len(test_csv))):\n    img_name = test_csv['id_code'][i]\n    img_path = os.path.join(testpath, img_name + '.png')\n    image = Image.open(img_path)\n    image = apply_transform(image)\n    TestImages[i] = image","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:11:59.936867Z","iopub.execute_input":"2023-12-05T20:11:59.937382Z","iopub.status.idle":"2023-12-05T20:13:59.067050Z","shell.execute_reply.started":"2023-12-05T20:11:59.937335Z","shell.execute_reply":"2023-12-05T20:13:59.065875Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 1928/1928 [01:59<00:00, 16.19it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split into train and validation sets(contribution)\ntrain_num = int(0.8 * len(TrainImages))\nval_num = len(TrainImages) - train_num\n\nTrain_Images = TrainImages[:train_num]\nValImages = TrainImages[train_num:]\nTrain_Labels = TrainLabels[:train_num]\nValLabels = TrainLabels[train_num:]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:13:59.068930Z","iopub.execute_input":"2023-12-05T20:13:59.069646Z","iopub.status.idle":"2023-12-05T20:13:59.084087Z","shell.execute_reply.started":"2023-12-05T20:13:59.069600Z","shell.execute_reply":"2023-12-05T20:13:59.083093Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Define datasets and dataloaders\ntrainDataset = TensorDataset(Train_Images, Train_Labels)\nvalDataset = TensorDataset(ValImages, ValLabels)\ntestDataset = TensorDataset(TestImages)\n\ntrainDataLoader = DataLoader(trainDataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\nvalDataLoader = DataLoader(valDataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\ntestDataLoader = DataLoader(testDataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:13:59.085815Z","iopub.execute_input":"2023-12-05T20:13:59.086534Z","iopub.status.idle":"2023-12-05T20:13:59.097697Z","shell.execute_reply.started":"2023-12-05T20:13:59.086489Z","shell.execute_reply":"2023-12-05T20:13:59.096365Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#(contribution)\nclass CustomModel(nn.Module):\n    def __init__(self):\n        super(CustomModel, self).__init__()\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.pool = GeM()\n\n        # Additional convolutional layers\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(0, 128)  # The input size will be set dynamically during the forward pass\n        self.fc2 = nn.Linear(128, 5)\n\n    def forward(self, x):\n        # Convolutional layers\n        x = self.conv1(x)\n        x = self.pool(x)\n\n        # Additional convolutional layers\n        x = self.conv2(x)\n        x = self.pool(x)\n\n        # Flatten the feature map\n        x = x.view(x.size(0), -1)\n\n        # Set the input size of fc1 dynamically\n        if self.fc1.in_features == 0:\n            self.fc1.in_features = x.size(1)\n            self.fc1 = nn.Linear(x.size(1), 128)\n\n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        return x\n\n    \nmodel = CustomModel()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:13:59.099790Z","iopub.execute_input":"2023-12-05T20:13:59.100251Z","iopub.status.idle":"2023-12-05T20:13:59.136561Z","shell.execute_reply.started":"2023-12-05T20:13:59.100213Z","shell.execute_reply":"2023-12-05T20:13:59.135165Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Move the model to the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:13:59.138468Z","iopub.execute_input":"2023-12-05T20:13:59.138890Z","iopub.status.idle":"2023-12-05T20:13:59.152823Z","shell.execute_reply.started":"2023-12-05T20:13:59.138850Z","shell.execute_reply":"2023-12-05T20:13:59.151640Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"CustomModel(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): GeM(p=3.0000, eps=1e-06)\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (fc1): Linear(in_features=0, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Loss, optimizer, scheduler\ncriterion = nn.SmoothL1Loss()\noptimizer = optim.Adam(model.parameters(), lr=0.0000015)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:13:59.156426Z","iopub.execute_input":"2023-12-05T20:13:59.156874Z","iopub.status.idle":"2023-12-05T20:13:59.164443Z","shell.execute_reply.started":"2023-12-05T20:13:59.156834Z","shell.execute_reply":"2023-12-05T20:13:59.163252Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Training loop\niterations = 25\ntrainLoss = []\n\nfor epoch in range(iterations):\n    runningLoss = 0\n    model.train()\n    \n    for data in tqdm.tqdm(trainDataLoader):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.long().to(device)\n        inputs = inputs / 255\n\n        outputs = model(inputs)\n\n        # Ensure that the size of labels matches the size of the output\n        labels = labels.unsqueeze(1)  # Add a singleton dimension at position 1\n\n        loss = criterion(F.log_softmax(outputs, dim=1), labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        runningLoss += loss.item()\n\n    avgTrainLoss = runningLoss / (train_num / 32)\n    trainLoss.append(avgTrainLoss)\n\n    # Validation logic here\n\n    scheduler.step()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:13:59.165983Z","iopub.execute_input":"2023-12-05T20:13:59.166810Z","iopub.status.idle":"2023-12-05T20:45:50.187668Z","shell.execute_reply.started":"2023-12-05T20:13:59.166763Z","shell.execute_reply":"2023-12-05T20:45:50.185958Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"  0%|          | 0/184 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:928: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([16, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n 99%|█████████▉| 183/184 [01:10<00:00,  2.55it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:928: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n100%|██████████| 184/184 [01:10<00:00,  2.60it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.59it/s]\n100%|██████████| 184/184 [01:12<00:00,  2.55it/s]\n100%|██████████| 184/184 [01:12<00:00,  2.53it/s]\n100%|██████████| 184/184 [01:12<00:00,  2.52it/s]\n100%|██████████| 184/184 [01:43<00:00,  1.78it/s]\n100%|██████████| 184/184 [01:15<00:00,  2.45it/s]\n100%|██████████| 184/184 [01:16<00:00,  2.39it/s]\n100%|██████████| 184/184 [01:12<00:00,  2.55it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.60it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.59it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.62it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.62it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.60it/s]\n100%|██████████| 184/184 [01:51<00:00,  1.65it/s]\n100%|██████████| 184/184 [01:12<00:00,  2.53it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.60it/s]\n100%|██████████| 184/184 [01:11<00:00,  2.56it/s]\n100%|██████████| 184/184 [01:14<00:00,  2.47it/s]\n100%|██████████| 184/184 [01:13<00:00,  2.51it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.60it/s]\n100%|██████████| 184/184 [01:10<00:00,  2.59it/s]\n100%|██████████| 184/184 [01:48<00:00,  1.69it/s]\n100%|██████████| 184/184 [01:13<00:00,  2.50it/s]\n100%|██████████| 184/184 [01:12<00:00,  2.54it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Testing loop\nmodel.eval()\nTestLabels = torch.LongTensor(len(test_csv), 1928)\nall_predictions = []\n\nfor i in range(10):\n    test_pred = np.array([])\n\n    for data in tqdm.tqdm(testDataLoader):\n        inputs = data[0]\n        inputs = inputs / 255\n        outputs = model(inputs)\n\n        _, predicted = torch.max(outputs, 1)\n        test_pred = np.append(test_pred, predicted.cpu().numpy())\n\n    all_predictions.append(test_pred)\n\n    TestLabels[i] = torch.from_numpy(test_pred).unsqueeze(0)\n\nTestLabels = (torch.sum(TestLabels, dim=0)) / 10\nTestLabels = TestLabels.numpy().astype(int)\n\n# Flatten all predictions from different iterations\nall_predictions_flat = np.concatenate(all_predictions)\n\n# Compute accuracy\ntrue_labels = TestLabels  # Provide the true labels for the test dataset\naccuracy = np.sum(np.array_equal(all_predictions_flat, true_labels)) / len(true_labels)\n\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Display predictions\nprint(\"Predictions:\", all_predictions_flat)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:50:00.584420Z","iopub.execute_input":"2023-12-05T20:50:00.585007Z","iopub.status.idle":"2023-12-05T20:52:25.520975Z","shell.execute_reply.started":"2023-12-05T20:50:00.584943Z","shell.execute_reply":"2023-12-05T20:52:25.519465Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 121/121 [00:14<00:00,  8.14it/s]\n100%|██████████| 121/121 [00:14<00:00,  8.27it/s]\n100%|██████████| 121/121 [00:15<00:00,  7.90it/s]\n100%|██████████| 121/121 [00:14<00:00,  8.35it/s]\n100%|██████████| 121/121 [00:14<00:00,  8.09it/s]\n100%|██████████| 121/121 [00:14<00:00,  8.31it/s]\n100%|██████████| 121/121 [00:13<00:00,  9.07it/s]\n100%|██████████| 121/121 [00:12<00:00,  9.39it/s]\n100%|██████████| 121/121 [00:14<00:00,  8.07it/s]\n100%|██████████| 121/121 [00:14<00:00,  8.16it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 82.63%\nPredictions: [1. 1. 1. ... 1. 1. 1.]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}